name: CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

jobs:
  test:
    name: Test Suite
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        node-version: [18.x, 20.x]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run type checking
        run: npm run type-check

      - name: Run linting
        run: npm run lint

      - name: Run formatting check
        run: npm run format:check

      - name: Run unit tests
        run: npm run test:unit
        env:
          CI: true

      - name: Run tests with coverage
        run: npm run test:coverage
        env:
          CI: true

      - name: Upload coverage reports to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage/lcov.info
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

      - name: Check coverage threshold
        run: |
          echo "Checking coverage threshold..."
          npm run test:coverage > coverage-output.txt 2>&1
          COVERAGE=$(grep "All files" coverage-output.txt | awk '{print $10}' | sed 's/%//' || echo "0")
          echo "Current coverage: ${COVERAGE}%"
          
          if [ -z "$COVERAGE" ] || [ "$COVERAGE" = "0" ]; then
            echo "❌ Could not determine coverage percentage"
            exit 1
          fi
          
          # Use bash arithmetic instead of bc (which is not available in GitHub Actions)
          # Extract integer part only for comparison
          COVERAGE_INT=$(echo "$COVERAGE" | cut -d. -f1)
          if [ "$COVERAGE_INT" -lt "40" ]; then
            echo "❌ Coverage $COVERAGE% is below minimum threshold of 40%"
            exit 1
          else
            echo "✅ Coverage $COVERAGE% meets minimum threshold"
          fi

      - name: Archive test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.node-version }}
          path: |
            coverage/
            *.log

  build:
    name: Build
    runs-on: ubuntu-latest
    needs: test

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build TypeScript
        run: npm run build

      - name: Verify build artifacts
        run: |
          if [ ! -d "dist" ]; then
            echo "❌ Build failed - dist directory not found"
            exit 1
          fi
          if [ ! -f "dist/server.js" ]; then
            echo "❌ Build failed - server.js not found"
            exit 1
          fi
          if [ ! -f "dist/claude-executor.js" ]; then
            echo "❌ Build failed - claude-executor.js not found"  
            exit 1
          fi
          echo "✅ Build artifacts verified successfully"

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-output-${{ github.sha }}
          path: dist/
          retention-days: 7

  security:
    name: Security Audit
    runs-on: ubuntu-latest
    needs: test

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run security audit
        run: |
          echo "Running npm security audit..."
          npm audit --audit-level high || {
            echo "High-severity vulnerabilities found. Please review and fix."
            exit 1
          }

      - name: Check for dependency vulnerabilities
        run: |
          echo "Checking for known vulnerabilities..."
          npm audit --json > audit-results.json 2>/dev/null || true
          
          if [ -s audit-results.json ]; then
            VULNERABILITIES=$(cat audit-results.json | jq '.metadata.vulnerabilities.total // 0' 2>/dev/null || echo "0")
            if [ "$VULNERABILITIES" -gt 0 ]; then
              echo "⚠️ Found $VULNERABILITIES vulnerabilities"
              npm audit
            else
              echo "✅ No vulnerabilities found"
            fi
          else
            echo "✅ No audit issues detected"
          fi

  integration:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [test, build]
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-output-${{ github.sha }}
          path: dist/

      - name: Create mock claude command
        run: |
          mkdir -p mock-bin
          cat > mock-bin/claude << 'EOF'
          #!/bin/bash
          echo '{"type":"system","subtype":"init","session_id":"mock-session-123"}'
          echo '{"type":"assistant","message":{"content":[{"type":"text","text":"Mock response from CI"}],"stop_reason":"end_turn"}}'
          EOF
          chmod +x mock-bin/claude
          echo "$PWD/mock-bin" >> $GITHUB_PATH

      - name: Start server in background
        run: |
          npm start &
          SERVER_PID=$!
          echo "SERVER_PID=$SERVER_PID" >> $GITHUB_ENV
          echo "Started server with PID: $SERVER_PID"

      - name: Wait for server to start
        run: |
          echo "Waiting for server to start..."
          for i in {1..30}; do
            if curl -f http://localhost:3000/api/claude -X POST -H "Content-Type: application/json" -d '{"prompt":"test"}' >/dev/null 2>&1; then
              echo "✅ Server is responding"
              break
            fi
            if [ $i -eq 30 ]; then
              echo "❌ Server failed to start within 30 seconds"
              exit 1
            fi
            echo "Attempt $i/30..."
            sleep 1
          done

      - name: Test Claude API endpoint
        run: |
          echo "Testing Claude API endpoint..."
          RESPONSE=$(curl -s -w "%{http_code}" -X POST http://localhost:3000/api/claude \
            -H "Content-Type: application/json" \
            -d '{"prompt": "Hello from CI"}')
          
          HTTP_CODE=$(echo "$RESPONSE" | tail -c 4)
          if [ "$HTTP_CODE" != "200" ]; then
            echo "❌ Claude API test failed with status $HTTP_CODE"
            exit 1
          fi
          echo "✅ Claude API test passed"

      - name: Test OpenAI API endpoint
        run: |
          echo "Testing OpenAI API endpoint..."
          RESPONSE=$(curl -s -w "%{http_code}" -X POST http://localhost:3000/v1/chat/completions \
            -H "Content-Type: application/json" \
            -d '{"messages": [{"role": "user", "content": "Hello"}], "stream": true}')
          
          HTTP_CODE=$(echo "$RESPONSE" | tail -c 4)
          if [ "$HTTP_CODE" != "200" ]; then
            echo "❌ OpenAI API test failed with status $HTTP_CODE"
            exit 1
          fi
          echo "✅ OpenAI API test passed"

      - name: Test API error handling
        run: |
          echo "Testing API error handling..."
          # Test missing prompt
          RESPONSE=$(curl -s -w "%{http_code}" -X POST http://localhost:3000/api/claude \
            -H "Content-Type: application/json" \
            -d '{}')
          
          HTTP_CODE=$(echo "$RESPONSE" | tail -c 4)
          if [ "$HTTP_CODE" != "400" ]; then
            echo "❌ Error handling test failed - expected 400, got $HTTP_CODE"
            exit 1
          fi
          echo "✅ API error handling test passed"

      - name: Stop server for E2E tests
        run: |
          if [ ! -z "$SERVER_PID" ]; then
            kill $SERVER_PID 2>/dev/null || true
            echo "Server stopped for E2E tests"
            sleep 2
          fi

      - name: Run E2E Tests
        run: |
          echo "Running E2E tests with mock Claude CLI..."
          # Set PATH to include our mock claude
          export PATH="$PWD/mock-bin:$PATH"
          
          # Run the E2E tests (they will start their own servers)
          npm run test:e2e:openai || {
            echo "❌ OpenAI E2E tests failed"
            exit 1
          }
          
          echo "✅ E2E tests passed"

      - name: Stop server
        if: always()
        run: |
          if [ ! -z "$SERVER_PID" ]; then
            kill $SERVER_PID 2>/dev/null || true
            echo "Server stopped"
          fi

  e2e-tests:
    name: E2E Tests (OpenAI Compatibility)
    runs-on: ubuntu-latest
    needs: [test, build]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-output-${{ github.sha }}
          path: dist/

      - name: Create enhanced mock claude command
        run: |
          mkdir -p mock-bin
          cat > mock-bin/claude << 'EOF'
          #!/bin/bash
          
          # Mock Claude CLI for E2E tests
          echo '{"type":"system","subtype":"init","session_id":"e2e-test-'$(date +%s)'"}'
          
          # Simulate thinking (optional)
          if [ $((RANDOM % 2)) -eq 1 ]; then
            echo '{"type":"assistant","message":{"content":[{"type":"thinking","text":"Processing request..."}],"stop_reason":null}}'
          fi
          
          # Simulate tool use
          echo '{"type":"assistant","message":{"content":[{"type":"text","text":"I understand your request."},{"type":"tool_use","id":"toolu_e2e'$(date +%s)'","name":"Read","input":{"file_path":"/test/file.txt"}}],"stop_reason":null}}'
          
          # Tool result
          echo '{"type":"tool_result","tool_use_id":"toolu_e2e'$(date +%s)'","content":"Mock file content for E2E testing"}'
          
          # Final response
          echo '{"type":"assistant","message":{"content":[{"type":"text","text":"Mock response for E2E testing completed successfully."}],"stop_reason":"end_turn"}}'
          EOF
          chmod +x mock-bin/claude
          echo "$PWD/mock-bin" >> $GITHUB_PATH

      - name: Run OpenAI Compatibility E2E Tests
        run: |
          echo "Running OpenAI compatibility E2E tests..."
          npm run test:e2e:openai
        env:
          CI: true

      - name: Run Python Client Integration Tests
        run: |
          echo "Running Python client integration E2E tests..."
          npm run test:e2e:python
        env:
          CI: true

      - name: Run Node.js Client Integration Tests
        run: |
          echo "Running Node.js client integration E2E tests..."
          npm run test:e2e:nodejs
        env:
          CI: true

      - name: Archive E2E test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-test-results
          path: |
            coverage/
            *.log
            tests/mock-claude*

  quality-gate:
    name: Quality Gate
    runs-on: ubuntu-latest
    needs: [test, build, security, e2e-tests]
    if: always()

    steps:
      - name: Check all jobs status
        run: |
          echo "=== Quality Gate Results ==="
          echo "Test job status: ${{ needs.test.result }}"
          echo "Build job status: ${{ needs.build.result }}"
          echo "Security job status: ${{ needs.security.result }}"
          echo "E2E Tests job status: ${{ needs.e2e-tests.result }}"
          echo "=========================="
          
          if [[ "${{ needs.test.result }}" != "success" ]]; then
            echo "❌ Tests failed"
            exit 1
          fi
          
          if [[ "${{ needs.build.result }}" != "success" ]]; then
            echo "❌ Build failed"
            exit 1
          fi
          
          if [[ "${{ needs.security.result }}" != "success" ]]; then
            echo "❌ Security checks failed"
            exit 1
          fi
          
          if [[ "${{ needs.e2e-tests.result }}" != "success" ]]; then
            echo "❌ E2E tests failed"
            exit 1
          fi
          
          echo "✅ All quality gates passed"

      - name: Generate quality summary
        run: |
          echo "## 🎉 Quality Gate Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Check | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| 🧪 Tests | ✅ Passed |" >> $GITHUB_STEP_SUMMARY
          echo "| 🔨 Build | ✅ Passed |" >> $GITHUB_STEP_SUMMARY
          echo "| 🔒 Security | ✅ Passed |" >> $GITHUB_STEP_SUMMARY
          echo "| 📊 Coverage | ✅ >40% |" >> $GITHUB_STEP_SUMMARY
          echo "| 🎯 Quality | ✅ All Gates Passed |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Ready for deployment!** 🚀" >> $GITHUB_STEP_SUMMARY

